---
  title: "Comparison of BQSR strategies for variant discovery in Guinea worm amplicon sequenced samples. "
author: "Jessica Ribado"
date:  "`r format(Sys.time(), '%Y-%m-%d')`"
output: pdf_document
---
  
```{r setup, include=FALSE}
# load libraries
for(p in c('vcfR', 'data.table', 'dplyr', 'tidyr', "ggplot2",
           'ggsci', 'ggforce', 'ggpubr', 'knitr')){
  if(!p %in% installed.packages()[,1]){
    print(p)
    install.packages(p, repos =  "https://cloud.r-project.org", dependencies = T )
    library(p, character.only = TRUE)
  }
  library(p, character.only = TRUE)
}

# set global options
options(datatable.fread.datatable=FALSE)
options(stringsAsFactors = FALSE)

# set directories
project_dir <- '/mnt/data/guinea_worm/processing'
output_dir <- file.path('/mnt/data/guinea_worm', 'recal_comparison', 'plots')
if (!dir.exists(output_dir)){ dir.create(output_dir) }

# set plotting theme
theme_j <- function () {
  theme_bw(base_size=16) %+replace%
    theme(
      # font sizes and color
      panel.background  = element_blank(),
      plot.background   = element_rect(fill="transparent", colour=NA),
      plot.title        = element_text(size = rel(.85)),
      strip.background  = element_rect(fill="transparent", colour=NA),
      strip.text        = element_text(face="bold", size=rel(.6)),
      axis.title        = element_text(size=rel(0.8)),
      axis.text         = element_text(size=rel(0.6), color="grey30"),
      # legend
      legend.title         = element_text(size=rel(0.8)),
      legend.text          = element_text(size=rel(0.6)),
      legend.background    = element_rect(fill="transparent", colour=NA),
      legend.key           = element_rect(fill="transparent", colour=NA),
      legend.justification = "top"
    )
}

theme_set(theme_j())
```

```{r setup_functions, include=FALSE}
################################################################################
# functions
# Haploidize dipload data from VCF file
vcf2haploid <- function(vcf, min_read_depth=5, proportion = 1){
  
  #  vcf <- vcfR::read.vcfR(vcf_files[[1]], verbose = FALSE)
  tmp_vcf <- vcf
  # reset heterozygous genotypes as a single representation
  gt <- extract.gt(tmp_vcf)
  # tmp_vcf@gt[,-1][is_het(gt)] <- "N"
  is.na(tmp_vcf@gt[,-1][is_het(gt)]) <- TRUE
  het_gt <- extract.gt(tmp_vcf)
  het_gt <- data.frame(apply(het_gt, 2, function(x) gsub("\\|", "\\/", x)))
  het_hap <- data.frame(apply(het_gt, 2, function(x) gsub("\\/.*", "", x)))

  # revert heterozygous calls to homozygous if majority of calls go to one allele
  tmp_vcf <- vcf
  gt <- extract.gt(tmp_vcf)
  is.na(tmp_vcf@gt[,-1][!is_het(gt)]) <- TRUE
  # Extract allele depths.
  ad <- extract.gt(tmp_vcf, element = "AD")
  ad1 <- masplit(ad, record = 1)
  ad2 <- masplit(ad, record = 2)
  freq1 <- ad1/(ad1+ad2)
  # create a copy of the matrix to convert to homozygous
  het_hap_adj <- het_hap
  het_hap_adj[freq1 >= proportion] <- "0"
  het_hap_adj[freq1 <= 1-proportion] <- "1"
  
  # remove genotypes with less than the minimum read depth
  tmp_vcf <- vcf
  total_dp <- extract.gt(tmp_vcf, element = 'DP', as.numeric = TRUE)
  is.na(het_hap_adj) <- is.na(total_dp) <- total_dp < min_read_depth
   
  # paste with other sample information
  gt2 <- extract.gt(tmp_vcf, extract = FALSE)
  is.na(gt2) <- is.na(het_hap_adj)
  gt_merge <- matrix(paste(as.matrix(het_hap_adj), gt2, sep=":"), nrow=nrow(gt), dimnames=dimnames(gt))
  is.na(gt_merge[gt_merge == "NA:NA"]) <- TRUE
  tmp_vcf@gt[,-1] <- gt_merge
  
  # apply filter
  # filter samples with low read depth 
  samp_keep <- (colSums(is.na(het_hap_adj))/nrow(het_hap_adj) < 0.5) & 
    sapply(names(het_hap_adj), function(y) !grepl(y, "BAT"))
  het_samp_rm <- het_hap_adj[, samp_keep]
  
  # filter out sites with a majority proportion of missing reads
  gt_counts <- cbind.data.frame(
     ref =  rowSums(het_samp_rm == "0", na.rm=T),
     missing = rowSums(is.na(het_samp_rm))
   )
  gt_counts$alt = ncol(het_samp_rm) - rowSums(gt_counts)
   
  site_keep_sing <- dplyr::filter(gt_counts, alt > 0 & ref > 0 & missing < 0.1 * ncol(het_hap_adj))
  site_keep <- dplyr::filter(gt_counts, alt > 1 & ref > 1 & missing < 0.1 * ncol(het_hap_adj))
  
  tmp_vcf@gt <- tmp_vcf@gt[, c(TRUE, samp_keep)]
  tmp_vcf <- tmp_vcf[rownames(het_hap_adj) %in% row.names(site_keep), ]
  
  # organize summary statistics for filtering 
  summary_df <- data.frame(rbind(
    vcf_n_samples = ncol(het_hap),
    vcf_n_variants = nrow(het_hap),
    site_min_read_depth = min_read_depth,
    heterozygous_threshold = paste(1 -proportion, proportion, sep=","),
    filt_n_samples = sum(samp_keep),
    filt_n_variants = nrow(site_keep_sing),
    filt_n_variants_singleton_excluded = nrow(site_keep)
  )) %>% tibble::rownames_to_column() 
  names(summary_df) <- c("summary", "value")
  
  return(list(summary = summary_df,
              vcf = tmp_vcf))
}  

# no longer needed - vcfR recodes alleles 
vcf2genotype <- function(tmp_vcf){
  gt_info <- data.frame(tmp_vcf@fix)
  gt_call <- extract.gt(tmp_vcf) 
  
  gt_alleles <- lapply(paste(gt_info$REF, gt_info$ALT, sep=","),
                       function(x) {unlist(strsplit(x, split="\\,"))})
  names(gt_alleles) <- paste(gt_info$CHROM, gt_info$POS, sep="_")

  recode <- apply(data.frame(gt_call) %>% tibble::rownames_to_column("POS"), 1, function(y){
      alleles = gt_alleles[[as.character(y[1])]]
      sapply(y[-1], function(y) ifelse(y != ".", gsub(y, alleles[as.numeric(y) + 1], y), y))
    })
  recode <- t(recode)
  row.names(recode) <- paste(gt_info$CHROM, gt_info$POS, sep="_")
  
  return(data.frame(recode) %>% tibble::rownames_to_column("POS"))
}

# recode clusters by their presence
grpid = function(x) match(x, unique(x))
cluster_recode <- function(cluster_counts, bqsr_call, kmer_threshold){
  cluster_sub <- dplyr::filter(cluster_counts %>% ungroup(), 
                               variant_recal == !!bqsr_call & kmer_threshold == !!kmer_threshold) %>%
    # dplyr::mutate(cluster_tmp = ifelse(count != 1, id, "Singleton")) %>%
    dplyr::left_join(., bc_overlap) %>%
    dplyr::mutate(bc_cluster = paste(Barcode, id, sep="_"),
                  bc_cluster = ifelse(count != 1, bc_cluster, "Singleton"))
    # dplyr::arrange(variant_recal, Barcode, kmer_threshold, desc(count)) %>%
    # dplyr::group_by(Barcode, cluster_tmp) %>%
    # dplyr::mutate(index = group_indices()) %>%
    # dplyr::group_by(Barcode) %>%
    # dplyr::mutate(id = index %>% grpid,
    #               bc_cluster = paste(Barcode, id, sep="_"),
    #               bc_cluster = ifelse(is.na(`SubmittedForNGS?`), NA,
    #                                   ifelse(cluster_tmp == 'singleton', 'Singleton', bc_cluster)))
    return(cluster_sub)
} 


# plotting functions
bc_colors <- c(ggsci::pal_futurama("planetexpress")(11)[-c(9)], "#7E6148B2", "grey50")
ggsci_pals <- c("red", "pink", "purple", "blue", "teal", "light-green", "lime", "amber", "brown", "deep-orange", "blue-grey") 
get_palette <- function(cluster){
  if(!cluster %in% seq(1,11)){
    default <- cbind.data.frame(cluster = "Singleton", color = "grey60")
  } else{
    clust_sub <- clusters[grepl(paste0("^", cluster, "_"), clusters)]
    if(length(clust_sub) == 0){
      length = 1
    } else{
      length = length(clust_sub)
    }
    clust_cols <- pal_material(palette = ggsci_pals[as.numeric(cluster)], reverse=T)(length)
    default <- cbind.data.frame(cluster = c(cluster, clust_sub), 
                                color = c(clust_cols[1], clust_cols))
  }
  return (default)
} 

# cluster node maps 
clust_recode_mapping <- function(recode_df){
  
  # set order of barcodes for plotting
  otu_ord <- c(seq(1,11), 
               unique(recode_df$bc_cluster)[!grepl("Singleton", unique(recode_df$bc_cluster))], 
               "Singleton")
  otu_color <- paste0('d3.scaleOrdinal() .domain([', 
                   paste0('"', paste(ggsci_cols$cluster, collapse='", "'), '"'),']) .range([', 
                   paste0('"', paste(ggsci_cols$color, collapse='", "'), '"'), '])')
  
  # plot
  otu_merge <- dplyr::filter(recode_df, !is.na(Barcode)) %>% unique()
  nodes <- data.frame(
    new_barcode=c(as.character(otu_merge$Barcode), 
    as.character(otu_merge$bc_cluster)) %>% unique())
  

  # With networkD3, connection must be provided using id, not using real name like in the links dataframe.. So   we need to reformat it.
  otu_merge$IDsource <- match(otu_merge$Barcode, nodes$new_barcode)-1 
  otu_merge$IDtarget <- match(otu_merge$bc_cluster, nodes$new_barcode)-1

  # Make the Network
  p <- sankeyNetwork(Links = otu_merge, Nodes = nodes,
              Source = "IDsource", Target = "IDtarget",
              Value = "Barcode", NodeID = "new_barcode", 
              colourScale=noquote(otu_color),
              sinksRight=FALSE)
  p
  
  file = paste0("recal", stringr::str_to_title(unique(recode_df$variant_recal)), "_", 
                gsub("kmer_", "0.", unique(recode_df$kmer_threshold)), "_",
                nrow(otu_merge), "samples.html")
  setwd(output_dir)
  saveNetwork(p, file=file, selfcontained = TRUE)
  webshot(file, gsub("html", "png", file), vwidth = 1000, vheight = 900)
}
```

## Introduction

Collaborators (Elizabeth Thiele and James Cotton) developed an amplicon panel consisting of 40 paired end primers to amplify 80% of the Guinea worm mitochondrial genome. Recently, we have reevaluated the original pipeline to identify variants to understand transmission at a finer scale.  

Ideas to improve the pipeline under comparison:
  
  * Remove deduplication steps to increase depth at sites. Difficult to discern PCR duplicates from biological duplicates with amplification protocol.
* Identify a set of known variants for recalibration from an independent set of samples characterized using WGS (Durrant et al. 2020, PLOS NTDs). Should allow for standardization of variant call recalibration for samples sequenced at different centers to avoid biases in recalibration from potentially missing portions of the genome. 
* Calling variants as diploid to remove calls that may be driven by heteroplasmy signals.

## Goal

Identify the differences in variant calls using either a known set of variants derived from an independent population or variants derived from the sequenced batch population.

Retaining duplicates and diploid calling should have a negligible effect on true signal. Diploid calling should lead to more filtered positions in the final calls. The positions used for recalibration may have an effect on identifying lower frequency alleles in the population. 

## Weighing a known set of variants for recalibration

Benefits:
  
* Standardization across sequencing batches, ideal for multiple centers running the protocol
* Faster processing with 1/3 of the steps
* Smaller memory footprint without intermediate BAM files
* Merging biological replicates across batches will be calibrated with the same sites ignored


Limitations:
  
  * Limited to the variants identified in training data set. Assumes training set contains enough diversity to identify a spread of representative sites.

Given the small training set sample size (54 samples) and the suggested high diversity of the Chad GW population, the limitation may have implications for reducing variants needed to group samples at a finer scale. 


## Known variant identification from Durrant et al. 2020

The data are available from the European Nucleotide Archive project PRJEB1236. Samples corresponding the the known variants are in 'NGS samples and accession numbers_withLabID.txt' provided by Elizabeth Thiele. These samples correspond to manuscript https://www.biorxiv.org/content/10.1101/808923v1.

We successfully downloaded files for $54$ samples. Samples were processed with duplicates removed (WGS, PCR duplicates detectable) with two rounds of recalibration. Variants were hard filtered using the recommendations set by GATK (https://gatk.broadinstitute.org/hc/en-us/articles/360035890471-Hard-filtering-germline-short-variants).  The first and second round of recalibration resulted in a single SNP addition in the second round at position 5971. Manual inspection of the individual genotypes for the 54 samples at this position, some samples have 'heterozygous' calls suggesting likely either heteroplasmy. Would be filtered out by low MAF in analyses, but call numbers (>10) for alternative alleles suggest this variant is a true signal and should be considered in recalibration. A total of $332$ variant were identified. Variants with a snapping or overlapping deletion as an alternative allele (*) were manually checked to confirm the second alternative allele present in samples are a non-reference homozygous call. 

Command line to get VCF files

```{r, eval=F}
snakemake -s ~/git/GWSpatialGenetics/ngs_processing/gw_processing.snakefile --configfile config.yaml -p --jobs 15

parallel "zcat 03_variant_calls/haplocall_{}/joint_genotypeFiltered.vcf.gz | grep -v ^# | cut -f1,2  > 04_variant_check/haplocall{}_positions.txt" ::: 0 1 2

diff 04_variant_check/haplocall1_positions.txt 04_variant_check/haplocall2_positions.txt

zcat 03_variant_calls/haplocall_2/joint_genotypeFiltered.vcf.gz | grep ^# > ~/git/GWSpatialGenetics/ngs_processing/input_files/gw_known_variants.vcf 
  zcat 03_variant_calls/haplocall_2/joint_genotypeFiltered.vcf.gz | grep -v ^# | -f1,2,3,4,5,6,7 >> ~/git/GWSpatialGenetics/ngs_processing/input_files/gw_known_variants.vcf
```

## Variant call comparisons

These comparisons include 96 samples from the first successful pilot of the amplicon panel that were received in September 2020. This sequencing batch is an ideal set for this comparison because 96 samples in a single plate had a higher per sample coverage compared to subsequent sequencing batches with 384 samples. 

However, it's also important to consider batch variation and sequencing depth differences on the called variants. Variants were called for all samples up to 10/2021 using both methods. 

*Note: Due to update calling variants with a ploid of $2$, we should not compare to the original sequencing run that called with a ploidy of $1$. The variant call comparisons are both with a ploidy of $2$. EICC will need to rerun all samples from the alignment step on regardless of the method decided on by the team.*

In addition to using GATK hard filtering suggestions, I've included a few additional manual variant filters around heterozygous calls:

* Excessive heterozygous calls (> 10% of the samples) 
* No alternative alleles after converting to haploid (i.e. alternative allele only observed in a heterozygous call)
* Alternative allele frequency equal to one (variant relative to the reference only)
* Singletons 


```{r load_data_gatk, echo = F, warning = F, eval=F}
gt_files <- c('/mnt/data/guinea_worm/processing/joint_calling_known/vcf_filter/round_20200928_jointGenotypeFiltered.txt',
             '/mnt/data/guinea_worm/processing/joint_calling_recal/vcf_filter/round_20200928_jointGenotypeFiltered.txt')
gt_list <- lapply(gt_files, gt_conversion)
names(gt_list) <- c("known", "identified")
gt_df <- dplyr::bind_rows(gt_list, .id="variant_recal") %>%
  tidyr::separate(ALT, c("ALT1", "ALT2"), sep=",") %>%
  dplyr::mutate(gt_group = ifelse(gt == paste(REF, REF, sep="/"), "REF_HOM",
                                  ifelse(gt == paste(ALT1, ALT1, sep="/") | gt == paste(ALT2, ALT2, sep="/"), "ALT_HOM", "HET")),
                gt_group = ifelse(is.na(gt_group) | gt == "./.", "MISSING", gt_group)) %>%
  dplyr::select(-gt) %>%
  tidyr::pivot_wider(names_from = "variant_recal", values_from = "gt_group") %>%
  dplyr::mutate(concordance = ifelse(is.na(known) | is.na(identified), "UNIQUE_VAR",
      ifelse(known == identified, "T", 
        ifelse((known == "MISSING" & identified == "HET") | (known == "MISSING" & identified == "MISSING"), "SAMPLE_FILTER",  "F"))))
```

```{r load_data_vcf, echo = F, warning = F, eval=F}
vcf_files <- c(paste(project_dir, 'joint_calling_known', 'vcf_files', 'round_202108_jointGenotypeFiltered.vcf.gz', sep="/"),
               paste(project_dir, 'joint_calling_recal', 'vcf_files', 'round_202108_jointGenotypeFiltered.vcf.gz', sep="/"))

tmp_vcfs <- lapply(vcf_files, function(y){
  org_vcf  <- vcfR::read.vcfR(y, verbose = FALSE)
  filt_vcf <- vcf2haploid(org_vcf)
  
  return(list(name = y, 
              summary = filt_vcf[[1]],
              org_vcf = org_vcf,
              filt_vcf = filt_vcf[[2]]))
              #gt_recode = gt_recode))
  })
names(tmp_vcfs) <- c("known", "identified")

# save filted vcfs
lapply(tmp_vcfs, function(y){
  vcf_name <- basename(y$name)
  recal <- gsub(".*calling_|/vcf_files.*", "\\2", y$name)
  out_vcf <- paste(gsub("/plots", "", output_dir), paste(gsub("_joint.*", "", vcf_name), recal, "jointHaploidFilter.vcf.gz", sep="_"), sep="/")
  vcfR::write.vcf(y$filt_vcf, out_vcf)
})

gt_summary <- bind_rows(lapply(tmp_vcfs, "[[", 2), .id="name") %>%
  tidyr::pivot_wider(names_from = name, values_from = value)
kable(gt_summary)
write.table(gt_summary, file = paste(gsub("plots", "", output_dir), "20211104_variantRecalSummary.tsv", sep="/"), quote = F, row.names = F, sep="\t")
```

```{r compare}
skip_gt <- c("N", ".")

gt_list <- lapply(lapply(tmp_vcfs, "[[", 4), function(y) {
  tmp_gt <- data.frame(extract.gt(y, element = "GT", return.alleles = TRUE))
  tmp_long <-  tibble::rownames_to_column(tmp_gt, "POS") %>%
    tidyr::pivot_longer(-POS, names_to = "sample", values_to = "allele") 
  return(tmp_long)
  })
names(gt_list) <- names(tmp_vcfs) 

gt_df <- dplyr::bind_rows(gt_list, .id="variant_recal") %>%
  tidyr::pivot_wider(names_from = 'variant_recal', values_from = 'allele') %>%
  dplyr::mutate_all(~replace(., is.na(.), ".")) %>%
  dplyr::mutate(concordance = ifelse(known %in% skip_gt & identified %in% skip_gt, "Both het/missing",
                  ifelse(known == identified, "Match",
                         ifelse((known %in% skip_gt) & !(identified %in% skip_gt), 'Known het/missing',
                                ifelse(!(known %in% skip_gt) & (identified %in% skip_gt), 'Identified het/missing',
                                        ifelse(known == "." & identified != ".", "Identified unique",
                                              ifelse(known != "." & identified == ".", "Known unique", 'Mismatch')))))))
```

There are `r length(unique(gt_df$sample))` samples have sufficient coverage, defined as at least 5 reads, and the `r length(unique(gt_df$POS))` variants identified in this sample population. 

How often do the positions correlate between the two runs?

```{r grouping,echo = F, warning = F}
gt_count <- count(gt_df, POS, concordance, .drop = FALSE) 
gt_category <- dplyr::group_by(gt_count, concordance) %>%
  dplyr::summarise(Sum = sum(n)) %>% ungroup %>%
  dplyr::mutate(Percent = round((Sum / sum(Sum))*100, 2)) %>%
  dplyr::arrange(desc(Sum))
kable(gt_category)
write.table(gt_category, file = paste(gsub("plots", "", output_dir), "20211104_variantDiffEnumerate.tsv", sep="/"), quote = F, row.names = F, sep="\t")
```

Less than 3% of all calls differ between the two recalibration strategies. Where do these differences lie? 

```{r discordant_plot, echo = F, warning = F}
gt_discord <- dplyr::filter(gt_count, concordance != "Match")
discord_pos <-  dplyr::filter(gt_df, POS %in% gt_discord$POS, concordance != "Match") %>%
  dplyr::mutate(POS = as.numeric(gsub(".*_", "", POS)))
  
discord_p <- ggplot(discord_pos, aes(y=factor(POS), x=sample, fill=concordance)) + geom_tile() +
  labs(x="Sample", y="Position") +
  theme(axis.text.x = element_blank())
discord_p
ggsave("bqsr_gt_differences.png", path=output_dir, 
       plot=discord_p, width=12, height=8, units=c("in"), dpi=300)
```

From the plot above showing which samples and genomic location are discordant between the calling strategies, we see that there are no apparent patterns for individual sites or samples which were already removed in previous steps. We do observe that there are sets of variants that would be eliminated using one call of the other (anything that is het/missing in either call scenario), but it doesn't appear biased. Good news is that we don't see homozygous call changes (mismatches) too often. 

**It seems using a known set of variants is sufficient to recall the same variants as an iterative recalibration set. However, I recommend rerunning ALL samples with a known set derived with all samples near the end of the project.**

